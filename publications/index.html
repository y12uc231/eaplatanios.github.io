<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <title>Anthony Platanios | publications</title>
  <meta name="description" content="My personal website.
">

  <link rel="shortcut icon" href="/assets/img/favicon.ico">

  <link rel="stylesheet" href="/assets/css/main.css">
  <link rel="canonical" href="/publications/">
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">
    
      <div class="site-social">
        <span class="header-name"><b>Anthony</b> Platanios</span>
        <span class="contacticon-small left">
          <a href="mailto:e.a.platanios@cs.cmu.edu"><i class="fa fa-envelope-square"></i></a>
          <a href="https://scholar.google.com/citations?userid=EFVk-mwAAAAJ" target="_blank" title="Google Scholar"><i class="ai ai-google-scholar-square"></i></a>
          <a href="https://www.github.com/eaplatanios" target="_blank" title="GitHub"><i class="fa fa-github-square"></i></a>
          <a href="https://www.linkedin.com/in/eplatanios" target="_blank" title="LinkedIn"><i class="fa fa-linkedin-square"></i></a>
          <a href="https://www.facebook.com/anthony.platanios" target="_blank" title="Facebook"><i class="fa fa-facebook-square"></i></a>
          <!-- <a href="https://twitter.com/" target="_blank" title="Twitter"><i class="fa fa-twitter-square"></i></a> -->
        </span>
      </div>
    
    <nav class="site-nav">

      <div class="trigger">
        <!-- About -->
        <a class="page-link" href="/">about</a>

        <!-- Blog -->
        <!-- <a class="page-link" href="/blog/">blog</a> -->

        <!-- Pages -->
        
          
        
          
            <a class="page-link" href="/cv/">cv</a>
          
        
          
        
          
            <a class="page-link" href="/projects/">projects</a>
          
        
          
            <a class="page-link" href="/publications/">publications</a>
          
        
          
            <a class="page-link" href="/teaching/">teaching</a>
          
        
          
        

      </div>
    </nav>

  </div>

</header>



    <div class="page-content">
      <div class="wrapper">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title">publications</h1>
    <h5 class="post-description"></h5>
    
  </header>

  <article class="post-content publications clearfix">
    
<h3 class="bibliography-year">2017</h3>
<ol class="bibliography"><li>
  
    <abbr><a href="https://arxiv.org" target="_blank">arXiv</a></abbr>
  


<div id="Platanios:2017:active_learning">
  
    <span class="title">Active Learning amidst Logical Knowledge.</span>
    <span class="author">
      
        
          
            
              <em>Platanios, Emmanouil A</em>,
            
          
        
      
        
          
            
              
                <a href="https://www.microsoft.com/en-us/research/people/akapoor/" target="_blank">Kapoor, Ashish</a>,
              
            
          
        
      
        
          
            and
            
              
                <a href="http://erichorvitz.com" target="_blank">Horvitz, Eric</a>
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In arXiv</em>
    
    
      2017
    
    </span>
  

  <span class="publication-links">
  
    <a class="abstract">Abstract</a>
  
  
  
    <a href="/assets/pdf/platanios_2017_active_learning/paper.pdf" target="_blank">PDF</a>
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Structured prediction is ubiquitous in applications of machine learning such as knowledge extraction and natural language processing. Structure often can be formulated in terms of logical constraints. We consider the question of how to perform efficient active learning in the presence of logical constraints among variables inferred by different classifiers. We propose several methods and provide theoretical results that demonstrate the inappropriateness of employing uncertainty guided sampling, a commonly used active learning method. Furthermore, experiments on ten different datasets demonstrate that the methods significantly outperform alternatives in practice. The results are of practical significance in situations where labeled data is scarce.</p>
  </span>
  
</div>
</li>
<li>
  
    <abbr><a href="http://www.nips.cc/" target="_blank">NIPS</a></abbr>
  


<div id="Platanios:2017:accuracy_estimation_logic">
  
    <span class="title">Estimating Accuracy from Unlabeled Data: A Probabilistic Logic Approach.</span>
    <span class="author">
      
        
          
            
              <em>Platanios, Emmanouil A</em>,
            
          
        
      
        
          
            
              
                <a href="https://www.microsoft.com/en-us/research/people/hoifung/" target="_blank">Poon, Hoifung</a>,
              
            
          
        
      
        
          
            
              
                <a href="http://erichorvitz.com" target="_blank">Horvitz, Eric</a>,
              
            
          
        
      
        
          
            and
            
              
                <a href="http://www.cs.cmu.edu/~tom/" target="_blank">Mitchell, Tom M</a>
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Neural Information Processing Systems</em>
    
    
      2017
    
    </span>
  

  <span class="publication-links">
  
    <a class="abstract">Abstract</a>
  
  
  
    <a href="/assets/pdf/platanios_2017_logic/paper.pdf" target="_blank">PDF</a>
  
  
    <a href="/assets/pdf/platanios_2017_logic/supplementary.pdf" target="_blank">Supplementary</a>
  
  
  
    <a href="/assets/pdf/platanios_2017_logic/poster.pdf" target="_blank">Poster</a>
  
  
  
  
    <a href="http://arxiv.org/abs/1705.07086" target="_blank">arXiv</a>
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>We propose an efﬁcient method to estimate the accuracy of classiﬁers using only unlabeled data. We consider a setting with multiple classiﬁcation problems where the target classes may be tied together through logical constraints. For example, a set of classes may be mutually exclusive, meaning that a data instance can belong to at most one of them. The proposed method is based on the intuition that: (i) when classiﬁers agree, they are more likely to be correct, and (ii) when the classiﬁers make a prediction that violates the constraints, at least one classiﬁer must be making an error. Experiments on four real-world data sets produce accuracy estimates within a few percent of the true accuracy, using solely unlabeled data. Our models also outperform existing state-of-the-art solutions in both estimating accuracies, and combining multiple classiﬁer outputs. The results emphasize the utility of logical constraints in estimating accuracy, thus validating our intuition.</p>
  </span>
  
</div>
</li></ol>

<h3 class="bibliography-year">2016</h3>
<ol class="bibliography"><li>
  
    <abbr><a href="http://www.icml.cc/" target="_blank">ICML</a></abbr>
  


<div id="Platanios:2016ti">
  
    <span class="title">Estimating Accuracy from Unlabeled Data: A Bayesian Approach.</span>
    <span class="author">
      
        
          
            
              <em>Platanios, Emmanouil A</em>,
            
          
        
      
        
          
            
              
                <a href="https://sites.google.com/site/kumaravinavadubey/" target="_blank">Dubey, Avinava</a>,
              
            
          
        
      
        
          
            and
            
              
                <a href="http://www.cs.cmu.edu/~tom/" target="_blank">Mitchell, Tom M</a>
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In International Conference in Machine Learning</em>
    
    
      2016
    
    </span>
  

  <span class="publication-links">
  
    <a class="abstract">Abstract</a>
  
  
  
    <a href="/assets/pdf/platanios_2016ti/platanios_2016ti.pdf" target="_blank">PDF</a>
  
  
    <a href="/assets/pdf/platanios_2016ti/platanios_2016ti_supp.pdf" target="_blank">Supplementary</a>
  
  
  
    <a href="/assets/pdf/platanios_2016ti/platanios_2016ti_poster.pdf" target="_blank">Poster</a>
  
  
    <a href="/assets/pdf/platanios_2016ti/platanios_2016ti_slides.pdf" target="_blank">Slides</a>
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>We consider the question of how unlabeled data can be used to estimate the true accuracy of learned classifiers, and the related question of how outputs from several classifiers performing the same task can be combined based on their estimated accuracies. To answer these questions, we first present a simple graphical model that performs well in practice. We then provide two nonparametric extensions to it that improve its performance. Experiments on two real-world data sets produce accuracy estimates within a few percent of the true accuracy, using solely unlabeled data. Our models also outperform existing state-of-the-art solutions in both estimating accuracies, and combining multiple classifier outputs.</p>
  </span>
  
</div>
</li></ol>

<h3 class="bibliography-year">2015</h3>
<ol class="bibliography"><li>
  
    <abbr><a href="http://www.aaai.org/" target="_blank">AAAI</a></abbr>
  


<div id="Mitchell:2015wo">
  
    <span class="title">Never-Ending Learning.</span>
    <span class="author">
      
        
          
            
              
                <a href="http://www.cs.cmu.edu/~tom/" target="_blank">Mitchell, Tom M</a>,
              
            
          
        
      
        
          
            
              
                <a href="http://www.cs.cmu.edu/~wcohen/" target="_blank">Cohen, William W</a>,
              
            
          
        
      
        
          
            
              
                <a href="http://www2.dc.ufscar.br/~estevam/" target="_blank">Hruschka Jr, Estevam R</a>,
              
            
          
        
      
        
          
            
              
                <a href="http://talukdar.net/" target="_blank">Pratim Talukdar, Partha</a>,
              
            
          
        
      
        
          
            
              
                <a href="http://www.cs.cmu.edu/~jbetter/" target="_blank">Betteridge, Justin</a>,
              
            
          
        
      
        
          
            
              
                <a href="http://www.cs.cmu.edu/~acarlson/" target="_blank">Carlson, Andrew</a>,
              
            
          
        
      
        
          
            
              
                <a href="http://allenai.org/team/bhavanad/" target="_blank">Dalvi, Bhanava</a>,
              
            
          
        
      
        
          
            
              
                <a href="http://www.cs.cmu.edu/~mg1/" target="_blank">Gardner, Matt</a>,
              
            
          
        
      
        
          
            
              
                Kisiel, Bryan,
              
            
          
        
      
        
          
            
              
                <a href="http://allenai.org/team/jayantk/" target="_blank">Krishnamurthy, Jayant</a>,
              
            
          
        
      
        
          
            
              
                <a href="http://www.cs.cmu.edu/~nlao/" target="_blank">Lao, Ni</a>,
              
            
          
        
      
        
          
            
              
                <a href="http://www.cs.cmu.edu/~krivard/" target="_blank">Mazaitis, Kathryn</a>,
              
            
          
        
      
        
          
            
              
                Mohamed, Thahir P,
              
            
          
        
      
        
          
            
              
                <a href="http://nakashole.com/" target="_blank">Nakashole, Ndapakula</a>,
              
            
          
        
      
        
          
            
              <em>Platanios, Emmanouil A</em>,
            
          
        
      
        
          
            
              
                <a href="http://aritter.github.io/" target="_blank">Ritter, Alan</a>,
              
            
          
        
      
        
          
            
              
                <a href="http://www.mehdisamadi.com/" target="_blank">Samadi, Mehdi</a>,
              
            
          
        
      
        
          
            
              
                <a href="http://burrsettles.com/" target="_blank">Settles, Burr</a>,
              
            
          
        
      
        
          
            
              
                <a href="http://www.cs.cmu.edu/~rcwang/" target="_blank">Wang, Richard C</a>,
              
            
          
        
      
        
          
            
              
                <a href="http://www.cs.cmu.edu/~dwijaya/" target="_blank">Wijaya, Derry</a>,
              
            
          
        
      
        
          
            
              
                <a href="http://www.cs.cmu.edu/~abhinavg/" target="_blank">Gupta, Abhinav</a>,
              
            
          
        
      
        
          
            
              
                <a href="http://www.cs.cmu.edu/~xinleic/" target="_blank">Chen, Xinlei</a>,
              
            
          
        
      
        
          
            
              
                Saparov, Abulhair,
              
            
          
        
      
        
          
            
              
                <a href="http://www.malcolmgreaves.io/" target="_blank">Greaves, Malcolm</a>,
              
            
          
        
      
        
          
            and
            
              
                <a href="http://staff.psc.edu/welling/" target="_blank">Welling, Joel</a>
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Association for the Advancement of Artificial Intelligence</em>
    
    
      2015
    
    </span>
  

  <span class="publication-links">
  
    <a class="abstract">Abstract</a>
  
  
  
    <a href="/assets/pdf/mitchell_2015wo/mitchell_2015wo.pdf" target="_blank">PDF</a>
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Whereas people learn many different types of knowledge from diverse experiences over many years, most current machine learning systems acquire just a single function or data model from just a single data set. We propose a neverending learning paradigm for machine learning, to better reflect the more ambitious and encompassing type of learning performed by humans. As a case study, we describe the Never-Ending Language Learner (NELL), which achieves some of the desired properties of a never-ending learner, and we discuss lessons learned. NELL has been learning to read the web 24 hours/day since January 2010, and so far has acquired a knowledge base with over 80 million confidenceweighted beliefs (e.g., servedWith(tea, biscuits)). NELL has also learned millions of features and parameters that enable it to read these beliefs from the web. Additionally, it has learned to reason over these beliefs to infer new beliefs, and is able to extend its ontology by synthesizing new relational predicates. NELL can be tracked online at http://rtw.ml.cmu.edu, and followed on Twitter at @CMUNELL.</p>
  </span>
  
</div>
</li>
<li>
  
    <abbr><a href="http://www.ml.cmu.edu/" target="_blank">CMU</a></abbr>
  


<div id="Platanios:2015ui">
  
    <span id="Platanios:2015ui">Platanios, E. A. (2015). <i>Estimating Accuracy from Unlabeled Data</i>. <i>Master’s Thesis at Carnegie Mellon University</i>.</span>
  

  <span class="publication-links">
  
    <a class="abstract">Abstract</a>
  
  
  
    <a href="/assets/pdf/platanios_2015ui/platanios_2015ui.pdf" target="_blank">PDF</a>
  
  
  
  
    <a href="/assets/pdf/platanios_2015ui/platanios_2015ui_poster.pdf" target="_blank">Poster</a>
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>We consider the question of how unlabeled data can be used to estimate the true accuracy of learned classiﬁers. This is an important question for any autonomous learning system that must estimate its accuracy without supervision, and also when classiﬁers trained from one data distribution must be applied to a new distribution (e.g., document classiﬁers trained on one text corpus are to be applied to a second corpus). We ﬁrst show how to estimate error rates exactly from unlabeled data when given a collection of competing classiﬁers that make independent errors, based on the agreement rates between subsets of these classiﬁers. We further show that even when the competing classiﬁers do not make independent errors, both their accuracies and error dependencies can be estimated by making certain relaxed assumptions. We then present an alternative approach based on graphical models that also allows us to combine the outputs of the classiﬁers into a single output label. A simple graphical model is introduced that performs well in practice. Then, two nonparametric extensions to it are presented, that signiﬁcantly improve its performance. Experiments on two real-world data sets produce accuracy estimates within a few percent of the true accuracy, using solely unlabeled data. We also obtain results demonstrating our graphical model approaches beating alternative methods for combining the classiﬁers’ outputs. These results are of practical signiﬁcance in situations where labeled data is scarce and shed light on the more general question of how the consistency among multiple functions is related to their true accuracies.</p>
  </span>
  
</div>
</li></ol>

<h3 class="bibliography-year">2014</h3>
<ol class="bibliography"><li>
  
    <abbr><a href="http://www.auai.org/" target="_blank">UAI</a></abbr>
  


<div id="Platanios:2014ti">
  
    <span class="title">Estimating Accuracy from Unlabeled Data.</span>
    <span class="author">
      
        
          
            
              <em>Platanios, Emmanouil A</em>,
            
          
        
      
        
          
            
              
                <a href="http://www.cs.cmu.edu/~avrim/" target="_blank">Blum, Avrim</a>,
              
            
          
        
      
        
          
            and
            
              
                <a href="http://www.cs.cmu.edu/~tom/" target="_blank">Mitchell, Tom M</a>
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Conference on Uncertainty in Artificial Intelligence</em>
    
    
      2014
    
    </span>
  

  <span class="publication-links">
  
    <a class="abstract">Abstract</a>
  
  
  
    <a href="/assets/pdf/platanios_2014ti/platanios_2014ti.pdf" target="_blank">PDF</a>
  
  
  
    <a href="/assets/pdf/platanios_2014ti/platanios_2014ti_addendum.pdf" target="_blank">Addendum</a>
  
  
    <a href="/assets/pdf/platanios_2014ti/platanios_2014ti_poster.pdf" target="_blank">Poster</a>
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>We consider the question of how unlabeled data can be used to estimate the true accuracy of learned classifiers. This is an important question for any autonomous learning system that must estimate its accuracy without supervision, and also when classifiers trained from one data distribution must be applied to a new distribution (e.g., document classifiers trained on one text corpus are to be applied to a second corpus). We first show how to estimate error rates exactly from unlabeled data when given a collection of competing classifiers that make independent errors, based on the agreement rates between subsets of these classifiers. We further show that even when the competing classifiers do not make independent errors, both their accuracies and error dependencies can be estimated by making certain relaxed assumptions. Experiments on two data real-world data sets produce estimates within a few percent of the true accuracy, using solely unlabeled data. These results are of practical significance in situations where labeled data is scarce and shed light on the more general question of how the consistency among multiple functions is related to their true accuracies.</p>
  </span>
  
</div>
</li>
<li>
  
    <abbr><a href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?reload=true&amp;punumber=34" target="_blank">PAMI</a></abbr>
  


<div id="Platanios:2014gp">
  
    <span class="title">Gaussian Process-Mixture Conditional Heteroscedasticity.</span>
    <span class="author">
      
        
          
            
              <em>Platanios, Emmanouil A</em>,
            
          
        
      
        
          
            and
            
              
                <a href="https://www.cut.ac.cy/eecei/staff/sotirios.chatzis/" target="_blank">Chatzis, Sotirios P</a>
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>
    
    
      2014
    
    </span>
  

  <span class="publication-links">
  
    <a class="abstract">Abstract</a>
  
  
  
    <a href="/assets/pdf/platanios_2014gp/platanios_2014gp.pdf" target="_blank">PDF</a>
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Generalized autoregressive conditional heteroscedasticity (GARCH) models have long been considered as one of the most successful families of approaches for volatility modeling in ﬁnancial return series. In this paper, we propose an alternative approach based on methodologies widely used in the ﬁeld of statistical machine learning. Speciﬁcally, we propose a novel nonparametric Bayesian mixture of Gaussian process regression models, each component of which models the noise variance process that contaminates the observed data as a separate latent Gaussian process driven by the observed data. This way, we essentially obtain a Gaussian process-mixture conditional heteroscedasticity (GPMCH) model for volatility modeling in ﬁnancial return series. We impose a nonparametric prior with power-law nature over the distribution of the model mixture components, namely the Pitman-Yor process prior, to allow for better capturing modeled data distributions with heavy tails and skewness. Finally, we provide a copula-based approach for obtaining a predictive posterior for the covariances over the asset returns modeled by means of a postulated GPMCH model. We evaluate the efﬁcacy of our approach in a number of benchmark scenarios, and compare its performance to state-of-the-art methodologies.</p>
  </span>
  
</div>
</li></ol>

<h3 class="bibliography-year">2012</h3>
<ol class="bibliography"><li>
  
    <abbr><a href="http://www.nips.cc/" target="_blank">NIPS</a></abbr>
  


<div id="Platanios:2012uh">
  
    <span class="title">Nonparametric Mixtures of Multi-Output Heteroscedastic Gaussian Processes for Volatility Modeling.</span>
    <span class="author">
      
        
          
            
              <em>Platanios, Emmanouil A</em>,
            
          
        
      
        
          
            and
            
              
                <a href="https://www.cut.ac.cy/eecei/staff/sotirios.chatzis/" target="_blank">Chatzis, Sotirios P</a>
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Neural Information Processing Systems Workshop on Modern Nonparametric Methods in Machine Learning</em>
    
    
      2012
    
    </span>
  

  <span class="publication-links">
  
    <a class="abstract">Abstract</a>
  
  
  
    <a href="/assets/pdf/platanios_2012uh/platanios_2012uh.pdf" target="_blank">PDF</a>
  
  
  
  
    <a href="/assets/pdf/platanios_2012uh/platanios_2012uh_poster.pdf" target="_blank">Poster</a>
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>In this work, we present a nonparametric Bayesian method for multivariate volatility modeling. Our approach is based on postulation of a novel mixture of multioutput heteroscedastic Gaussian processes to model the covariance matrices of multiple assets. Speciﬁcally, we use the Pitman-Yor process prior as the non- parametric prior imposed over the components of our model, which are taken as multioutput heteroscedastic Gaussian processes obtained by introducing appropriate convolution kernels that combine simple heteroscedastic Gaussian processes under a multioutput scheme. We exhibit the efﬁcacy of our approach in a volatility prediction task.</p>
  </span>
  
</div>
</li></ol>


  </article>

  

</div>

      </div>
    </div>

    <footer class="site-footer">
  <div class="wrapper">
    &copy; Copyright 2017 Anthony Platanios.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.

    
  </div>
</footer>


    <!-- Load jQuery -->
<script src="//code.jquery.com/jquery-1.12.4.min.js"></script>

<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>





<!-- Code -->
<link href="https://fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet">
<script src="/assets/js/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>

<!-- Include custom icon fonts -->
<link rel="stylesheet" href="/assets/css/font-awesome.min.css">
<link rel="stylesheet" href="/assets/css/academicons.min.css">

<!-- Google Analytics -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-54519238-1', 'auto');
  ga('send', 'pageview');
</script>


  </body>

</html>
